#!/bin/bash

#SBATCH --job-name=fold_multi
#SBATCH -D /home/jflucier/projects/def-marechal/programs/Marechal_pipelines/environment/test.colabfold.multi
#SBATCH -o /home/jflucier/projects/def-marechal/programs/Marechal_pipelines/environment/test.colabfold.multi/slurm-%A_%a.out
#SBATCH --account=def-marechal
#SBATCH --time=2:00:00
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:1
#SBATCH --mem=40G

set -ex

## uncomment one of these env
#AF_VERSION=2.3.1
#AF_VERSION=2.3.2

ENV=/home/jflucier/projects/def-marechal/programs/colabfold_af${AF_VERSION}_env/bin/activate

module load gcc/9.3.0 cuda/11.4 openmpi/4.0.3 openmm/8.0.0 mmseqs2/14-7e284 hh-suite/3.3.0 hmmer/3.2.1

source ${ENV}

export TF_FORCE_UNIFIED_MEMORY="1"
export XLA_PYTHON_CLIENT_MEM_FRACTION="4.0"
export XLA_PYTHON_CLIENT_ALLOCATOR="platform"
export TF_FORCE_GPU_ALLOW_GROWTH="true"

export WORK=/lustre06/project/6003342/programs/Marechal_pipelines/environment/test.colabfold.multi
export IN=${WORK}/colabfold.af${AF_VERSION}.multi/0.a3m
export OUT=${WORK}/colabfold.af${AF_VERSION}.multi
export DOWNLOAD_DIR=/project/def-marechal/programs/colabfold_db

echo "running fold on /lustre06/project/6003342/programs/Marechal_pipelines/environment/test.colabfold.multi/DTX1.fa"
colabfold_batch \
--use-gpu-relax --amber --num-relax 3 \
--num-models 3 \
--num-recycle 30 --recycle-early-stop-tolerance 0.5 \
--model-type auto \
--data $DOWNLOAD_DIR \
${IN} \
${OUT}

echo "done!"


