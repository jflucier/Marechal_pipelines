#!/bin/bash

#SBATCH --job-name=DTX1_mono
#SBATCH -D /home/jflucier/projects/def-marechal/programs/Marechal_pipelines/environment/test.colabfold.mono
#SBATCH -o /home/jflucier/projects/def-marechal/programs/Marechal_pipelines/environment/test.colabfold.mono/slurm-%A_%a.out
#SBATCH --account=def-marechal
#SBATCH --time=1:00:00
#SBATCH --cpus-per-task=8
#SBATCH --gres=gpu:1
#SBATCH --mem=40G

set -ex

## uncomment one of these env
#ENV=/home/jflucier/projects/def-marechal/programs/colabfold_af2.3.1_env/bin/activate
#ENV=/home/jflucier/projects/def-marechal/programs/colabfold_af2.3.2_env/bin/activate

module load gcc/9.3.0 cuda/11.4 openmpi/4.0.3 openmm/8.0.0 mmseqs2/14-7e284 hh-suite/3.3.0 hmmer/3.2.1

source ${ENV}

export TF_FORCE_UNIFIED_MEMORY="1"
export XLA_PYTHON_CLIENT_MEM_FRACTION="4.0"
export XLA_PYTHON_CLIENT_ALLOCATOR="platform"
export TF_FORCE_GPU_ALLOW_GROWTH="true"

export WORK=/lustre06/project/6003342/programs/Marechal_pipelines/environment/test.colabfold.mono
export IN=${WORK}/colabfold.af2.3.1.mono/0.a3m
export OUT=${WORK}/colabfold.af2.3.1.mono
export DOWNLOAD_DIR=/project/def-marechal/programs/colabfold_db

echo "running fold on /lustre06/project/6003342/programs/Marechal_pipelines/environment/test.colabfold.mono/DTX1.fa"
colabfold_batch \
--use-gpu-relax --amber --num-relax 3 \
--num-models 3 \
--num-recycle 30 --recycle-early-stop-tolerance 0.5 \
--model-type auto \
--data $DOWNLOAD_DIR \
${IN} \
${OUT}

echo "done!"


