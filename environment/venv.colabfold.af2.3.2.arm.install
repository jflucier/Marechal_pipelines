### install and test colabfold (alphafold 2.3.2)
# deja install:
# gcc 13.1.1
# cuda V12.3.107
# cudnn v.8.8.0 (to install)

# setup cuda
#export PATH=/home/jflucier/perl5/bin:/home/jflucier/miniconda3/condabin:/home/jflucier/.local/bin:/home/jflucier/bin:/usr/share/Modules/bin:/opt/rh/gcc-toolset-13/root/usr/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin

# cudacore setup
export CMAKE_PREFIX_PATH="/usr/local/cuda-11.8":$CMAKE_PREFIX_PATH
export CPATH="/usr/local/cuda-11.8/include":$CPATH
export CPATH="/usr/local/cuda-11.8/extras/CUPTI/include":$CPATH
export CPATH="/usr/local/cuda-11.8/nvvm/include":$CPATH
export LIBRARY_PATH="/usr/local/cuda-11.8/lib64":$LIBRARY_PATH
#export LIBRARY_PATH="/usr/local/cuda-11.8/stubs/lib64":$LIBRARY_PATH
export LIBRARY_PATH="/usr/local/cuda-11.8/nvvm/lib64":$LIBRARY_PATH
export PATH="/usr/local/cuda-11.8/bin":$PATH
export PATH="/usr/local/cuda-11.8/nvvm/bin":$PATH
export EBROOTCUDACORE="/usr/local/cuda-11.8"
export EBVERSIONCUDACORE="11.8.0"
export EBDEVELCUDACORE="/usr/local/cuda-11.8"
export PATH="/usr/local/cuda-11.8":$PATH
export CUDA_HOME="/usr/local/cuda-11.8"
export CUDA_ROOT="/usr/local/cuda-11.8"
export CUDA_PATH="/usr/local/cuda-11.8"

# cuda setup
export EBROOTCUDA="/usr/local/cuda-11.8"
export EBVERSIONCUDA="11.8.0"
export EBDEVELCUDA="/usr/local/cuda-11.8"

# cudnn setup
export CMAKE_PREFIX_PATH="/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive":$CMAKE_PREFIX_PATH
export CPATH="/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/include":$CPATH
export LIBRARY_PATH="/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/lib":$LIBRARY_PATH
export EBROOTCUDNN="/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive"
export EBVERSIONCUDNN="8.9.7"
export EBDEVELCUDNN="/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive"


mkdir /home/def-marechal/programs
cd /home/def-marechal/programs
# pytorch
virtualenv --no-download  /home/def-marechal/programs/test_env
source  /home/def-marechal/programs/test_env/bin/activate
#pip install --no-index --upgrade pip
#pip3 install torch
git clone --recursive https://github.com/pytorch/pytorch
pip install cmake ninja
cd pytorch
pip install pyyaml
export LD_LIBRARY_PATH=/usr/local/cuda-11.8/targets/sbsa-linux/lib
export LD_LIBRARY_PATH=/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/lib:$LD_LIBRARY_PATH
pip install typing_extensions
python setup.py develop

# tensorflow
virtualenv --no-download /home/def-marechal/programs/tensor_env
source /home/def-marechal/programs/tensor_env/bin/activate
pip install --upgrade pip

# not working
#pip install tensorflow[and-cuda]

# install bazel
wget https://github.com/bazelbuild/bazel/releases/download/5.0.0/bazel-5.0.0-linux-arm64
chmod a+x bazel-5.0.0-linux-arm64
ln -s bazel-5.0.0-linux-arm64 bazel
export PATH=/home/def-marechal/programs:$PATH
git clone https://github.com/tensorflow/tensorflow.git
cd tensorflow
git checkout v2.9.0
export cuda=Y
./configure

#Do you wish to build TensorFlow with ROCm support? [y/N]: N
#Do you wish to build TensorFlow with CUDA support? [y/N]: y
#Do you wish to build TensorFlow with TensorRT support? [y/N]: N
#Please specify the CUDA SDK version you want to use. [Leave empty to default to CUDA 11]: 11.8
#Please specify the cuDNN version you want to use. [Leave empty to default to cuDNN 2]: 8.9.7
#Please specify the locally installed NCCL version you want to use. [Leave empty to use http://github.com/nvidia/nccl]:
#Please specify the comma-separated list of base paths to look for CUDA libraries and headers. [Leave empty to use the default]:
#/usr/local/cuda-11.8,/usr/local/cuda-11.8/nvvm,/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/lib,/usr/local/cuda-11.8/targets/sbsa-linux/lib,/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/lib,/usr/local/cudnn-linux-sbsa-8.9.7.29_cuda11-archive/include,/home/def-marechal/programs/nccl_2.16.5-1+cuda11.8_aarch64/include,
#Please note that each additional compute capability significantly increases your build time and binary size, and that TensorFlow only
# supports compute capabilities >= 3.5 [Default is: 3.5,7.0]:9.0
#Do you want to use clang as CUDA compiler? [y/N]: y
#Nogood? Do you wish to download a fresh release of clang? (Experimental) [y/N]: N
#Noggod? Please specify which clang should be used as device and host compiler. [Default is ]: /usr/lib64/clang

Do you want to use clang as CUDA compiler? [y/N]: N
Please specify which gcc should be used by nvcc as the host compiler. [Default is /usr/bin/gcc]:

#Please specify optimization flags to use during compilation when bazel option "--config=opt" is specified [Default is -Wno-sign-compare]:
#Would you like to interactively configure ./WORKSPACE for Android builds? [y/N]: N
#Preconfigured Bazel build configs. You can use any of the below by adding "--config=<>" to your build command. See .bazelrc for more details.
#	--config=mkl         	# Build with MKL support.
#	--config=mkl_aarch64 	# Build with oneDNN and Compute Library for the Arm Architecture (ACL).
#	--config=monolithic  	# Config for mostly static monolithic build.
#	--config=numa        	# Build with NUMA support.
#	--config=dynamic_kernels	# (Experimental) Build kernels into separate shared objects.
#	--config=v1          	# Build with TensorFlow 1 API instead of TF 2 API.
#Preconfigured Bazel build configs to DISABLE default on features:
#	--config=nogcp       	# Disable GCP support.
#	--config=nonccl      	# Disable NVIDIA NCCL support.

#need to patch: https://github.com/tensorflow/tensorflow/commit/a76f797b9cd4b9b15bec4c503b16236a804f676f
bazel --output_user_root=/home/def-marechal/programs/tensorflow/temp clean --expunge
bazel --output_user_root=/home/def-marechal/programs/tensorflow/temp build --repo_env=WHEEL_NAME=tensorflow --config=opt --config=cuda --config=mkl_aarch64 //tensorflow/tools/pip_package:wheel
#As a result, generated wheel will be located in bazel-bin/tensorflow/tools/pip_package/wheel_house/

# urgh not working

# lets try easybuild
virtualenv --no-download /home/def-marechal/programs/tensor_env
source /home/def-marechal/programs/tensor_env/bin/activate
pip install --upgrade pip
export PATH=/home/def-marechal/programs/Lmod-8.7/lmod/lmod:$PATH



module load gcc/9.3.0 openmpi/4.0.3 cuda/11.4 cudnn/8.2.0 kalign/2.03 hmmer/3.2.1 openmm-alphafold/7.5.1 hh-suite/3.3.0 python/3.8 mmseqs2/14-7e284
virtualenv --no-download /home/jflucier/projects/def-marechal/programs/colabfold_af2.3.2_env
source /home/jflucier/projects/def-marechal/programs/colabfold_af2.3.2_env/bin/activate
pip install --no-index --upgrade pip
pip install --no-index alphafold==2.3.2
pip install --no-deps alphafold-colabfold==v2.3.6
pip install --no-deps "colabfold[alphafold]@git+https://github.com/sokrypton/ColabFold@v1.5.2" appdirs==1.4.4 py3Dmol==2.0.4 tqdm==4.66.1
pip install zipp
pip install --no-index pandas
pip install --no-index tensorflow==2.9
pip install --no-index matplotlib==3.2.2